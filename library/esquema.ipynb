{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### ML"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. Datos.\n",
    "\n",
    "A.  Detectar el tipo de problema: (clasificación / regresión)\n",
    "- clasificación = LogisticReggresion(LR), SVC, KNN, Decission Tree, Random Forest Classificator, XGBoost...)\n",
    "- Regresion = Regresion Lineal, non-linear Polinomica, SVR, Decission Tree Regressor, Random Forest Regressor, ...)\n",
    "\n",
    "B. EDA: Data Wrangling: \n",
    "- ¡¡Crear el modelo baseline!! para tener una referencia previa. \n",
    "- Webscraping, API, Json, CSV, BBDD (SQL/NoSQL), web\n",
    "- Correlaciones\n",
    "- Feature Engineering (Extracción de características): outliers, regex, NaNs, distribuciones, estandarizar, normalizar, encoding(dummies), duplicados, elminar columnas no relevantes. \n",
    "- Visualizar los datos para entenderlos. OJO CON LOS OUTLIERS PORQUE DEFORMAN EL MODELO.\n",
    "- Variables agregadas. (Columnas agregadas) (Grouby no es un agregado): media de otras columnas numéricas.\n",
    "- Ponderaciones de columnas. (Si multiplico por 2 le doy más peso a esa columna y le doy más peso dentro modelo y puede funcionarle mejor)\n",
    "- Eliminar columnas colineales.\n",
    "- Al final ¡¡Crear nuevo modelo baseline!! de referencia.\n",
    "\n",
    "C. X e y con reshape si hace falta (Maquetar los datos). Partir los datos en conjunto de entrenamiento y de test. Elegimos un % de train/test y semilla. \n",
    "\n",
    "D. Cross validation --> con el objetivo de saber cómo es el comportamiento de mi modelo para mis datos. (OJO: GridSearch ya lo hace pero al no entrenar el modelo tarda menos y puede interesar la prueba cross primero.). SE PUEDE PEDIR QUE AÑADA UNA CONDICIÓN SI BAJA MUCHO EL CROSS VALIDATION.\n",
    "\n",
    "E. GridSearch y Pipeline. RECOMENDACIÓN: NO USAR MUCHOS MÁS DE UN ALGORITMO A LA VEZ. UNA VARIABLE CON EL GridSearch POR CADA ALGORITMO!!\n",
    "\n",
    "F. Nos quedamos con el mejor modelo y probamos el score con el conjunto de TEST. Nos quedamos con el que mejor generalice. \n",
    "\n",
    "G. Guardamos para futuras pruebas y para estar relajados. \n",
    "    ((Podemos hacer guardados intermedios. For iteration % 1000 == 0: pickle.dump!))\n",
    "\n",
    "H. Entrenamos con todos los datos .fit(X, y) y guardamos el modelo entrenado con otro nombre. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "PONERLO EN PRODUCCIÓN EN UN STREAMLIT. SE METEN LOS DATOS Y SE LE DA A PREDICCIÓN PARA ESE DATO. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "LAS SEMILLAS DE FORMA ALEATORIA ES LA MEJOR FORMA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## XGBClassifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "source": [
    "## Trees"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  }
 ]
}